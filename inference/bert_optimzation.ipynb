{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate BERT & RoBERTa inference with DeepSpeed-Inference\n",
    "\n",
    "In this session, you will learn how to optimize Hugging Face Transformers models for GPU inference using [DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/). The session will show you how to apply state-of-the-art optimization techniques using [DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/). \n",
    "This session will focus on single GPU inference on BERT and RoBERTa models. \n",
    "By the end of this session, you will know optimize your Hugging Face Transformers models (BERT, RoBERTa) using DeepSpeed-Inference. We are going to optimize a DistilBERT model for Question Answering, which was fine-tuned on the SQuAD dataset to decrease the latency from 7ms to 3ms for a sequence lenght of 128.\n",
    "\n",
    "You will learn how to:\n",
    "1. Setup Development Environment\n",
    "2. Load vanilla BERT model and set baseline\n",
    "3. Optimize BERT for GPU using DeepSpeeds `InferenceEngine`\n",
    "4. Evaluate the performance and speed\n",
    "\n",
    "Let's get started! ðŸš€\n",
    "\n",
    "_This tutorial was created and run on an g4dn.xlarge AWS EC2 Instance including a NVIDIA T4._\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Intro: What is DeepSpeed-Inference\n",
    "\n",
    "[DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/) is an extension of the [DeepSpeed](https://www.deepspeed.ai/) framework focused on inference workloads.  [DeepSpeed Inference](https://www.deepspeed.ai/#deepspeed-inference) combines model parallelism technology such as tensor, pipeline-parallelism, with custom optimzed cuda kernels.\n",
    "DeepSpeed provides a seamless inference mode for compatible transformer based models trained using DeepSpeed, Megatron, and HuggingFace. For list of compatible models please see [here](https://github.com/microsoft/DeepSpeed/blob/master/deepspeed/module_inject/replace_policy.py).\n",
    "As mentioned DeepSpeed-Inference integrates model-parallelism techniques allowing you so run multi-GPU inference for LLM, like [BLOOM](https://huggingface.co/bigscience/bloom) with 176 billion parameters.\n",
    "If you want to learn more about DeepSpeed inference: \n",
    "* [Paper: DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale](https://arxiv.org/pdf/2207.00032.pdf)\n",
    "* [Blog: Accelerating large-scale model inference and training via system optimizations and compression](https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Development Environment\n",
    "\n",
    "Our first step is to install Deepspeed, along with PyTorch, Transfromers and some other libraries. Running the following cell will install all the required packages.\n",
    "\n",
    "_Note: You need a machine with a GPU and a compatible CUDA installed. You can check this by running `nvidia-smi` in your terminal. If you have a correct environment you should statistics abour your GPU._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch==1.12.0\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.13.0\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.0) (4.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from torchvision==0.13.0) (9.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from torchvision==0.13.0) (1.23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.0) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.0) (2.0.12)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "Successfully installed torch-1.12.0+cu113 torchvision-0.13.0+cu113\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepspeed in /home/ubuntu/.local/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (1.23.2)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (21.3)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from deepspeed) (1.9.1)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (8.0.0)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (1.12.0+cu113)\n",
      "Requirement already satisfied: hjson in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from deepspeed) (4.64.0)\n",
      "Requirement already satisfied: ninja in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (1.10.2.3)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.8/site-packages (from deepspeed) (5.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from packaging->deepspeed) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic->deepspeed) (4.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers[sentencepiece]==4.21.1 in /home/ubuntu/.local/lib/python3.8/site-packages (4.21.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]==4.21.1) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]==4.21.1) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (1.23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]==4.21.1) (4.64.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]==4.21.1) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (2022.7.25)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (0.1.97)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers[sentencepiece]==4.21.1) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]==4.21.1) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers[sentencepiece]==4.21.1) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]==4.21.1) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]==4.21.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]==4.21.1) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]==4.21.1) (2022.5.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/ubuntu/.local/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: evaluate[evaluator]==0.2.2 in /home/ubuntu/.local/lib/python3.8/site-packages (0.2.2)\n",
      "Requirement already satisfied: seqeval in /home/ubuntu/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (3.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate[evaluator]==0.2.2) (2022.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (0.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (0.18.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate[evaluator]==0.2.2) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate[evaluator]==0.2.2) (4.64.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (1.4.3)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (0.70.13)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (1.23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate[evaluator]==0.2.2) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.7.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (1.9.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.8/site-packages (from evaluate[evaluator]==0.2.2) (4.21.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from seqeval) (1.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate[evaluator]==0.2.2) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate[evaluator]==0.2.2) (4.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate[evaluator]==0.2.2) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from packaging->evaluate[evaluator]==0.2.2) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate[evaluator]==0.2.2) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate[evaluator]==0.2.2) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate[evaluator]==0.2.2) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate[evaluator]==0.2.2) (3.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate[evaluator]==0.2.2) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas->evaluate[evaluator]==0.2.2) (2.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers->evaluate[evaluator]==0.2.2) (2022.7.25)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers->evaluate[evaluator]==0.2.2) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate[evaluator]==0.2.2) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!DS_BUILD_TRANSFORMER_INFERENCE=1  pip install deepspeed\n",
    "!pip install transformers[sentencepiece]==4.21.1\n",
    "!pip install datasets evaluate[evaluator]==0.2.2 seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start. Lets make sure we all packages are installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch \n",
    "\n",
    "# check deepspeed installation\n",
    "report = !python3 -m deepspeed.env_report\n",
    "r = re.compile('.*transformer_inference.*YES.*')\n",
    "assert any(r.match(line) for line in report) == True, \"DeepSpeed Inference not correct installed\"\n",
    "\n",
    "# check cuda and torch version\n",
    "torch_version, cuda_version = torch.__version__.split(\"+\")\n",
    "torch_version = \".\".join(torch_version.split(\".\")[:2])\n",
    "cuda_version = f\"{cuda_version[2:4]}.{cuda_version[4:]}\"\n",
    "r = re.compile(f'.*torch.*{torch_version}.*')\n",
    "assert any(r.match(line) for line in report) == True, \"Wrong Torch version\"\n",
    "r = re.compile(f'.*cuda.*{cuda_version}.*')\n",
    "assert any(r.match(line) for line in report) == True, \"Wrong Cuda version\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load vanilla BERT model and set baseline\n",
    "\n",
    "After we setup our environment we create a baseline for our model. We use the [dslim/bert-large-NER](https://huggingface.co/dslim/bert-large-NER) a fine-tuned BERT-large model on on the English version of the standard [CoNLL-2003 Named Entity Recognition](https://www.aclweb.org/anthology/W03-0419.pdf) dataset achieving an f1 score `95.7%`.\n",
    "\n",
    "To create our baseline we load the model with `transformers` and create a `token-classification` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9971501, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.9986046, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Model Repository on huggingface.co\n",
    "model_id=\"dslim/bert-large-NER\"\n",
    "\n",
    "# Load Model and Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# Create a pipeline for token classification\n",
    "token_clf = pipeline(\"token-classification\", model=model, tokenizer=tokenizer,device=0)\n",
    "\n",
    "# Text pipeline\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "ner_results = token_clf(example)\n",
    "print(ner_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Baseline with `evaluate` using the `evaluator` and the `conll2003` dataset. The Evaluator class allows us to evaluate a model/pipeline on a dataset using a defined metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/ubuntu/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-b6771e194accd0b2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score for our model is 95.7593027153872.2f\n",
      "Overall f1 score for our model is 95.7593027153872.2f\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load eval dataset\n",
    "eval_dataset = load_dataset(\"conll2003\", split=\"validation\")\n",
    "\n",
    "# define evaluator\n",
    "task_evaluator = evaluator(\"token-classification\")\n",
    "\n",
    "# run baseline\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=token_clf,\n",
    "    data=eval_dataset,\n",
    "    metric=\"seqeval\",\n",
    ")\n",
    "\n",
    "print(f\"Overall f1 score for our model is {results['overall_f1']*100:.2f}\")\n",
    "print(f\"The avg. Latency of the model is {results['latency_in_seconds']*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieves an f1 score of `95.8%` on the CoNLL-2003 dataset with a average latency across the dataset of `18.9ms`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimize BERT for GPU using DeepSpeeds `InferenceEngine`\n",
    "\n",
    "init: https://deepspeed.readthedocs.io/en/latest/inference-init.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-15 15:15:52,979] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.0, git-hash=unknown, git-branch=unknown\n",
      "[2022-08-15 15:15:52,980] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference_op.cpython-38-x86_64-linux-gnu.so: undefined symbol: curandCreateGenerator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForTokenClassification\u001b[39m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# init deepspeed inference engine\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=11'>12</a>\u001b[0m ds_model \u001b[39m=\u001b[39m deepspeed\u001b[39m.\u001b[39;49minit_inference(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=12'>13</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,      \u001b[39m# Transformers models\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=13'>14</a>\u001b[0m     mp_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,        \u001b[39m# Number of GPU\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=14'>15</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mhalf, \u001b[39m# dtype of the weights (fp16)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=15'>16</a>\u001b[0m     \u001b[39m# injection_policy={\"BertLayer\" : HFBertLayerPolicy}, # replace BertLayer with DS HFBertLayerPolicy\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=16'>17</a>\u001b[0m     replace_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=17'>18</a>\u001b[0m     replace_with_kernel_inject\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# replace the model with the kernel injector\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=22'>23</a>\u001b[0m ds_clf \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtoken-classification\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39mds_model, tokenizer\u001b[39m=\u001b[39mtokenizer,device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bt4/home/ubuntu/transformers-deepspeed/inference/bert_optimzation.ipynb#ch0000009vscode-remote?line=23'>24</a>\u001b[0m example \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMy name is Wolfgang and I live in Berlin\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/__init__.py:292\u001b[0m, in \u001b[0;36minit_inference\u001b[0;34m(model, triangular_masking, mp_size, training_mp_size, mpu, ep_group, expert_mp_group, checkpoint, dtype, injection_policy, replace_method, quantization_setting, replace_with_kernel_inject, return_tuple, ep_size, moe, moe_experts, moe_type, args, enable_cuda_graph, save_mp_checkpoint_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=245'>246</a>\u001b[0m \u001b[39m\"\"\"Initialize the DeepSpeed InferenceEngine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=246'>247</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=247'>248</a>\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=283'>284</a>\u001b[0m \u001b[39m    A deepspeed.InferenceEngine wrapped model.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=284'>285</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=285'>286</a>\u001b[0m log_dist(\u001b[39m\"\u001b[39m\u001b[39mDeepSpeed info: version=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, git-hash=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, git-branch=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=286'>287</a>\u001b[0m     __version__,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=287'>288</a>\u001b[0m     __git_hash__,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=288'>289</a>\u001b[0m     __git_branch__),\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=289'>290</a>\u001b[0m          ranks\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=291'>292</a>\u001b[0m engine \u001b[39m=\u001b[39m InferenceEngine(model,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=292'>293</a>\u001b[0m                          triangular_masking,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=293'>294</a>\u001b[0m                          mp_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=294'>295</a>\u001b[0m                          training_mp_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=295'>296</a>\u001b[0m                          ep_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=296'>297</a>\u001b[0m                          mpu,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=297'>298</a>\u001b[0m                          ep_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=298'>299</a>\u001b[0m                          expert_mp_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=299'>300</a>\u001b[0m                          checkpoint,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=300'>301</a>\u001b[0m                          dtype,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=301'>302</a>\u001b[0m                          injection_policy,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=302'>303</a>\u001b[0m                          return_tuple,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=303'>304</a>\u001b[0m                          replace_method,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=304'>305</a>\u001b[0m                          quantization_setting,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=305'>306</a>\u001b[0m                          replace_with_kernel_inject,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=306'>307</a>\u001b[0m                          moe,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=307'>308</a>\u001b[0m                          moe_experts,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=308'>309</a>\u001b[0m                          moe_type,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=309'>310</a>\u001b[0m                          args,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=310'>311</a>\u001b[0m                          enable_cuda_graph,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=311'>312</a>\u001b[0m                          save_mp_checkpoint_path)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/__init__.py?line=313'>314</a>\u001b[0m \u001b[39mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py:136\u001b[0m, in \u001b[0;36mInferenceEngine.__init__\u001b[0;34m(self, model, triangular_masking, mp_size, training_mp_size, ep_size, mpu, ep_group, expert_mp_group, checkpoint, dtype, injection_dict, return_tuple, replace_method, quantization_setting, replace_with_kernel_inject, moe, moe_experts, moe_type, config, enable_cuda_graph, save_mp_checkpoint_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=123'>124</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_injection_policy(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=124'>125</a>\u001b[0m             client_module,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=125'>126</a>\u001b[0m             injection_policy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=132'>133</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint \u001b[39mif\u001b[39;00m replace_with_kernel_inject \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=133'>134</a>\u001b[0m             save_mp_checkpoint_path\u001b[39m=\u001b[39msave_mp_checkpoint_path)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=134'>135</a>\u001b[0m \u001b[39melif\u001b[39;00m replace_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=135'>136</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_injection_policy(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=136'>137</a>\u001b[0m         return_tuple\u001b[39m=\u001b[39;49mreturn_tuple,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=137'>138</a>\u001b[0m         replace_with_kernel_inject\u001b[39m=\u001b[39;49mreplace_with_kernel_inject,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=138'>139</a>\u001b[0m         moe\u001b[39m=\u001b[39;49mmoe,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=139'>140</a>\u001b[0m         moe_experts\u001b[39m=\u001b[39;49mmoe_experts,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=140'>141</a>\u001b[0m         moe_type\u001b[39m=\u001b[39;49mmoe_type,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=141'>142</a>\u001b[0m         training_mp_size\u001b[39m=\u001b[39;49mtraining_mp_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=142'>143</a>\u001b[0m         checkpoint_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheckpoint \u001b[39mif\u001b[39;49;00m replace_with_kernel_inject \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=143'>144</a>\u001b[0m         save_mp_checkpoint_path\u001b[39m=\u001b[39;49msave_mp_checkpoint_path)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=145'>146</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mcurrent_device()\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=146'>147</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py:329\u001b[0m, in \u001b[0;36mInferenceEngine._apply_injection_policy\u001b[0;34m(self, client_module, injection_policy, return_tuple, replace_with_kernel_inject, moe, moe_experts, moe_type, training_mp_size, checkpoint_dir, save_mp_checkpoint_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=314'>315</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply_injection_policy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=315'>316</a>\u001b[0m                             client_module\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=316'>317</a>\u001b[0m                             injection_policy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=323'>324</a>\u001b[0m                             checkpoint_dir\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=324'>325</a>\u001b[0m                             save_mp_checkpoint_path\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=325'>326</a>\u001b[0m     checkpoint \u001b[39m=\u001b[39m SDLoaderFactory\u001b[39m.\u001b[39mget_sd_loader_json(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=326'>327</a>\u001b[0m         checkpoint_dir,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=327'>328</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_engine) \u001b[39mif\u001b[39;00m checkpoint_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=328'>329</a>\u001b[0m     replace_transformer_layer(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=329'>330</a>\u001b[0m         client_module,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=330'>331</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=331'>332</a>\u001b[0m         triangular_masking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtriangular_masking,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=332'>333</a>\u001b[0m         policy\u001b[39m=\u001b[39;49minjection_policy,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=333'>334</a>\u001b[0m         mp_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmp_world_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=334'>335</a>\u001b[0m         mp_group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmp_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=335'>336</a>\u001b[0m         ep_group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mep_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=336'>337</a>\u001b[0m         expert_mp_group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpert_mp_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=337'>338</a>\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=338'>339</a>\u001b[0m         fp16\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype \u001b[39m==\u001b[39;49m torch\u001b[39m.\u001b[39;49mhalf),\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=339'>340</a>\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=340'>341</a>\u001b[0m         return_tuple\u001b[39m=\u001b[39;49mreturn_tuple,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=341'>342</a>\u001b[0m         quantize\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype \u001b[39m==\u001b[39;49m torch\u001b[39m.\u001b[39;49mint8),\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=342'>343</a>\u001b[0m         quantize_settings\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantization_scales,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=343'>344</a>\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantize_merge_count,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=344'>345</a>\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp_extra_grouping,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=345'>346</a>\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantize_groups),\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=346'>347</a>\u001b[0m         replace_with_kernel_inject\u001b[39m=\u001b[39;49mreplace_with_kernel_inject,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=347'>348</a>\u001b[0m         moe\u001b[39m=\u001b[39;49mmoe,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=348'>349</a>\u001b[0m         moe_experts\u001b[39m=\u001b[39;49mmoe_experts,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=349'>350</a>\u001b[0m         moe_type\u001b[39m=\u001b[39;49mmoe_type,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=350'>351</a>\u001b[0m         training_mp_size\u001b[39m=\u001b[39;49mtraining_mp_size,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=351'>352</a>\u001b[0m         checkpoint_dict\u001b[39m=\u001b[39;49mcheckpoint,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=352'>353</a>\u001b[0m         save_mp_checkpoint_path\u001b[39m=\u001b[39;49msave_mp_checkpoint_path,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/inference/engine.py?line=353'>354</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:780\u001b[0m, in \u001b[0;36mreplace_transformer_layer\u001b[0;34m(orig_layer_impl, model, policy, micro_batch_size, config, seed, hidden_size, num_attention_heads, mp_size, training_mp_size, mp_group, ep_group, expert_mp_group, preln, fp16, local_rank, stochastic_mode, training, quantize, quantize_settings, triangular_masking, return_tuple, replace_with_kernel_inject, linear_layer_setting, moe, moe_experts, moe_type, checkpoint_dict, save_mp_checkpoint_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=775'>776</a>\u001b[0m             new_module \u001b[39m=\u001b[39m replace_wo_policy(child, _policy)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=777'>778</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m new_module\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=779'>780</a>\u001b[0m replaced_module \u001b[39m=\u001b[39m replace_module(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=780'>781</a>\u001b[0m                                  orig_class\u001b[39m=\u001b[39;49morig_layer_impl,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=781'>782</a>\u001b[0m                                  replace_fn\u001b[39m=\u001b[39;49mreplace_fn,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=782'>783</a>\u001b[0m                                  _replace_policy\u001b[39m=\u001b[39;49mpolicy)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=784'>785</a>\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=785'>786</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:962\u001b[0m, in \u001b[0;36mreplace_module\u001b[0;34m(model, orig_class, replace_fn, _replace_policy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=956'>957</a>\u001b[0m             policy\u001b[39m.\u001b[39mupdate({plcy\u001b[39m.\u001b[39m_orig_layer_class: (replace_fn, plcy)})\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=957'>958</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(policy\u001b[39m.\u001b[39mitems()) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m,\\\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=958'>959</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNo default policy found! Please specify your policy injection_policy (like \u001b[39m\u001b[39m{\u001b[39m\u001b[39mBertLayer:HFBEertLayerPolicy}).\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\\\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=959'>960</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mYou can find some samples here: https://github.com/microsoft/DeepSpeed/blob/master/deepspeed/module_inject/replace_policy.py\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=961'>962</a>\u001b[0m replaced_module, _ \u001b[39m=\u001b[39m _replace_module(model, policy)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=962'>963</a>\u001b[0m \u001b[39mreturn\u001b[39;00m replaced_module\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:989\u001b[0m, in \u001b[0;36m_replace_module\u001b[0;34m(model, policies, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=986'>987</a>\u001b[0m         layer_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=987'>988</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=988'>989</a>\u001b[0m         _, layer_id \u001b[39m=\u001b[39m _replace_module(child, policies, layer_id\u001b[39m=\u001b[39;49mlayer_id)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=990'>991</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, layer_id\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:989\u001b[0m, in \u001b[0;36m_replace_module\u001b[0;34m(model, policies, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=986'>987</a>\u001b[0m         layer_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=987'>988</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=988'>989</a>\u001b[0m         _, layer_id \u001b[39m=\u001b[39m _replace_module(child, policies, layer_id\u001b[39m=\u001b[39;49mlayer_id)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=990'>991</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, layer_id\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:989\u001b[0m, in \u001b[0;36m_replace_module\u001b[0;34m(model, policies, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=986'>987</a>\u001b[0m         layer_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=987'>988</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=988'>989</a>\u001b[0m         _, layer_id \u001b[39m=\u001b[39m _replace_module(child, policies, layer_id\u001b[39m=\u001b[39;49mlayer_id)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=990'>991</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, layer_id\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:979\u001b[0m, in \u001b[0;36m_replace_module\u001b[0;34m(model, policies, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=976'>977</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_children():\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=977'>978</a>\u001b[0m     \u001b[39mif\u001b[39;00m child\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39min\u001b[39;00m policies:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=978'>979</a>\u001b[0m         replaced_module \u001b[39m=\u001b[39m policies[child\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m][\u001b[39m0\u001b[39;49m](child,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=979'>980</a>\u001b[0m                                                        policies[child\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=980'>981</a>\u001b[0m                                                        layer_id)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=981'>982</a>\u001b[0m         \u001b[39msetattr\u001b[39m(model, name, replaced_module)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=982'>983</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, PipelineModule):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:768\u001b[0m, in \u001b[0;36mreplace_transformer_layer.<locals>.replace_fn\u001b[0;34m(child, _policy, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=764'>765</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=765'>766</a>\u001b[0m     \u001b[39m# copy relevant state from child -> new module\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=766'>767</a>\u001b[0m     \u001b[39mif\u001b[39;00m replace_with_kernel_inject:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=767'>768</a>\u001b[0m         new_module \u001b[39m=\u001b[39m replace_with_policy(child,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=768'>769</a>\u001b[0m                                          _policy,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=769'>770</a>\u001b[0m                                          triangular_masking,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=770'>771</a>\u001b[0m                                          inference\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=771'>772</a>\u001b[0m                                          preln\u001b[39m=\u001b[39;49m(_policy\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=772'>773</a>\u001b[0m                                                 \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m HFBertLayerPolicy),\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=773'>774</a>\u001b[0m                                          layer_id\u001b[39m=\u001b[39;49mlayer_id)\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=774'>775</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=775'>776</a>\u001b[0m         new_module \u001b[39m=\u001b[39m replace_wo_policy(child, _policy)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py:364\u001b[0m, in \u001b[0;36mreplace_transformer_layer.<locals>.replace_with_policy\u001b[0;34m(child, policy_cls, triangular_masking, inference, preln, layer_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=354'>355</a>\u001b[0m         new_module \u001b[39m=\u001b[39m transformer_inference\u001b[39m.\u001b[39mDeepSpeedMoEInference(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=355'>356</a>\u001b[0m             transformer_config,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=356'>357</a>\u001b[0m             mp_group\u001b[39m=\u001b[39mmp_group,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=359'>360</a>\u001b[0m             \u001b[39mif\u001b[39;00m expert_mp_group \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m expert_mp_group[num_experts],\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=360'>361</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=362'>363</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=363'>364</a>\u001b[0m         new_module \u001b[39m=\u001b[39m transformer_inference\u001b[39m.\u001b[39;49mDeepSpeedTransformerInference(\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=364'>365</a>\u001b[0m             transformer_config,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=365'>366</a>\u001b[0m             mp_group\u001b[39m=\u001b[39;49mmp_group,\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=366'>367</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=367'>368</a>\u001b[0m new_module\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mscale_attention \u001b[39m=\u001b[39m scale_attention\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=369'>370</a>\u001b[0m \u001b[39m# we want the weights in [input, output] shape\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=370'>371</a>\u001b[0m \u001b[39m# linear layer is created with [input, output] shape\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/module_inject/replace_module.py?line=371'>372</a>\u001b[0m \u001b[39m# transpose it here to reduce inference cost!\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py:769\u001b[0m, in \u001b[0;36mDeepSpeedTransformerInference.__init__\u001b[0;34m(self, config, mp_group, quantize_scales, quantize_groups, merge_count, mlp_extra_grouping, qkv_merging)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py?line=766'>767</a>\u001b[0m \u001b[39mif\u001b[39;00m inference_cuda_module \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py?line=767'>768</a>\u001b[0m     builder \u001b[39m=\u001b[39m op_builder\u001b[39m.\u001b[39mInferenceBuilder()\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py?line=768'>769</a>\u001b[0m     inference_cuda_module \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py?line=770'>771</a>\u001b[0m \u001b[39mif\u001b[39;00m DeepSpeedTransformerInference\u001b[39m.\u001b[39mlayer_id \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference.py?line=771'>772</a>\u001b[0m     log_dist(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeepSpeed-Inference config: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, [\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py:469\u001b[0m, in \u001b[0;36mOpBuilder.load\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py?line=465'>466</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, CUDAOpBuilder):\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py?line=466'>467</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massert_torch_info(torch_info)\n\u001b[0;32m--> <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py?line=468'>469</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mabsolute_name())\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py?line=469'>470</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py?line=470'>471</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit_load(verbose)\n",
      "File \u001b[0;32m/usr/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/importlib/__init__.py?line=124'>125</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:657\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:556\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1166\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/ubuntu/.local/lib/python3.8/site-packages/deepspeed/ops/transformer/inference/transformer_inference_op.cpython-38-x86_64-linux-gnu.so: undefined symbol: curandCreateGenerator"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,pipeline\n",
    "from transformers import pipeline\n",
    "from deepspeed.module_inject import HFBertLayerPolicy\n",
    "import deepspeed\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# init deepspeed inference engine\n",
    "ds_model = deepspeed.init_inference(\n",
    "    model=model,      # Transformers models\n",
    "    mp_size=1,        # Number of GPU\n",
    "    dtype=torch.half, # dtype of the weights (fp16)\n",
    "    # injection_policy={\"BertLayer\" : HFBertLayerPolicy}, # replace BertLayer with DS HFBertLayerPolicy\n",
    "    replace_method=\"auto\",\n",
    "    replace_with_kernel_inject=True, # replace the model with the kernel injector\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ds_clf = pipeline(\"token-classification\", model=ds_model, tokenizer=tokenizer,device=0)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = ds_clf(example)\n",
    "print(ner_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceEngine(\n",
       "  (module): BertForTokenClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-b6771e194accd0b2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score for our model is 95.76\n",
      "The avg. Latency of the model is 18.90ms\n"
     ]
    }
   ],
   "source": [
    "# run baseline\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=ds_clf,\n",
    "    data=eval_dataset,\n",
    "    metric=\"seqeval\",\n",
    ")\n",
    "\n",
    "print(f\"Overall f1 score for our model is {results['overall_f1']*100:.2f}\")\n",
    "print(f\"The avg. Latency of the model is {results['latency_in_seconds']*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
